[2025-10-09T03:00:08.535+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-09T03:00:08.608+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_analytics.run_spark_stream scheduled__2025-10-09T02:00:00+00:00 [queued]>
[2025-10-09T03:00:08.630+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_analytics.run_spark_stream scheduled__2025-10-09T02:00:00+00:00 [queued]>
[2025-10-09T03:00:08.631+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-10-09T03:00:08.672+0000] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): run_spark_stream> on 2025-10-09 02:00:00+00:00
[2025-10-09T03:00:08.704+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=2558) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-09T03:00:08.718+0000] {standard_task_runner.py:64} INFO - Started process 2560 to run task
[2025-10-09T03:00:08.713+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'restaurant_analytics', 'run_spark_stream', 'scheduled__2025-10-09T02:00:00+00:00', '--job-id', '239', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_dag.py', '--cfg-path', '/tmp/tmpz4fhry4m']
[2025-10-09T03:00:08.725+0000] {standard_task_runner.py:91} INFO - Job 239: Subtask run_spark_stream
[2025-10-09T03:00:08.925+0000] {task_command.py:426} INFO - Running <TaskInstance: restaurant_analytics.run_spark_stream scheduled__2025-10-09T02:00:00+00:00 [running]> on host 01b28d042a8a
[2025-10-09T03:00:09.262+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='quantruong1918@gmail.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='restaurant_analytics' AIRFLOW_CTX_TASK_ID='run_spark_stream' AIRFLOW_CTX_EXECUTION_DATE='2025-10-09T02:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-09T02:00:00+00:00'
[2025-10-09T03:00:09.267+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-09T03:00:09.284+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-09T03:00:09.287+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'export PYSPARK_PYTHON=/usr/local/bin/python && export PYSPARK_DRIVER_PYTHON=/usr/local/bin/python && /opt/spark/bin/spark-submit --master local[*] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 /opt/***/dags/spark_streaming.py']
[2025-10-09T03:00:09.350+0000] {subprocess.py:86} INFO - Output:
[2025-10-09T03:00:16.478+0000] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-10-09T03:00:16.863+0000] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2025-10-09T03:00:16.864+0000] {subprocess.py:93} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2025-10-09T03:00:16.882+0000] {subprocess.py:93} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2025-10-09T03:00:16.890+0000] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-af3d1d56-4b97-48fd-81ba-95e9b2e4d276;1.0
[2025-10-09T03:00:16.891+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-10-09T03:00:17.440+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
[2025-10-09T03:00:17.612+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
[2025-10-09T03:00:17.684+0000] {subprocess.py:93} INFO - 	found org.apache.kafka#kafka-clients;3.4.1 in central
[2025-10-09T03:00:17.749+0000] {subprocess.py:93} INFO - 	found org.lz4#lz4-java;1.8.0 in central
[2025-10-09T03:00:17.808+0000] {subprocess.py:93} INFO - 	found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2025-10-09T03:00:17.870+0000] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;2.0.7 in central
[2025-10-09T03:00:17.965+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2025-10-09T03:00:18.058+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2025-10-09T03:00:18.117+0000] {subprocess.py:93} INFO - 	found commons-logging#commons-logging;1.1.3 in central
[2025-10-09T03:00:18.156+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.0 in central
[2025-10-09T03:00:18.190+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-pool2;2.11.1 in central
[2025-10-09T03:00:18.251+0000] {subprocess.py:93} INFO - :: resolution report :: resolve 1337ms :: artifacts dl 28ms
[2025-10-09T03:00:18.252+0000] {subprocess.py:93} INFO - 	:: modules in use:
[2025-10-09T03:00:18.253+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
[2025-10-09T03:00:18.254+0000] {subprocess.py:93} INFO - 	commons-logging#commons-logging;1.1.3 from central in [default]
[2025-10-09T03:00:18.255+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-pool2;2.11.1 from central in [default]
[2025-10-09T03:00:18.257+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2025-10-09T03:00:18.258+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2025-10-09T03:00:18.259+0000] {subprocess.py:93} INFO - 	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
[2025-10-09T03:00:18.260+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
[2025-10-09T03:00:18.261+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
[2025-10-09T03:00:18.262+0000] {subprocess.py:93} INFO - 	org.lz4#lz4-java;1.8.0 from central in [default]
[2025-10-09T03:00:18.263+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;2.0.7 from central in [default]
[2025-10-09T03:00:18.264+0000] {subprocess.py:93} INFO - 	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
[2025-10-09T03:00:18.265+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-10-09T03:00:18.266+0000] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-10-09T03:00:18.267+0000] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-10-09T03:00:18.268+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-10-09T03:00:18.269+0000] {subprocess.py:93} INFO - 	|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
[2025-10-09T03:00:18.270+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-10-09T03:00:18.271+0000] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-af3d1d56-4b97-48fd-81ba-95e9b2e4d276
[2025-10-09T03:00:18.272+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-10-09T03:00:18.289+0000] {subprocess.py:93} INFO - 	0 artifacts copied, 11 already retrieved (0kB/19ms)
[2025-10-09T03:00:19.038+0000] {subprocess.py:93} INFO - 25/10/09 03:00:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-10-09T03:00:25.272+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SparkContext: Running Spark version 3.5.1
[2025-10-09T03:00:25.273+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SparkContext: OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
[2025-10-09T03:00:25.275+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SparkContext: Java version 17.0.16
[2025-10-09T03:00:25.324+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceUtils: ==============================================================
[2025-10-09T03:00:25.326+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-10-09T03:00:25.327+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceUtils: ==============================================================
[2025-10-09T03:00:25.328+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SparkContext: Submitted application: RestaurantStreaming
[2025-10-09T03:00:25.376+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-09T03:00:25.396+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceProfile: Limiting resource is cpu
[2025-10-09T03:00:25.398+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-10-09T03:00:25.598+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SecurityManager: Changing view acls to: ***
[2025-10-09T03:00:25.600+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SecurityManager: Changing modify acls to: ***
[2025-10-09T03:00:25.602+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SecurityManager: Changing view acls groups to:
[2025-10-09T03:00:25.603+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SecurityManager: Changing modify acls groups to:
[2025-10-09T03:00:25.604+0000] {subprocess.py:93} INFO - 25/10/09 03:00:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-10-09T03:00:26.527+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO Utils: Successfully started service 'sparkDriver' on port 40063.
[2025-10-09T03:00:26.653+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO SparkEnv: Registering MapOutputTracker
[2025-10-09T03:00:26.826+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO SparkEnv: Registering BlockManagerMaster
[2025-10-09T03:00:26.883+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-09T03:00:26.884+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-10-09T03:00:26.893+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-10-09T03:00:26.973+0000] {subprocess.py:93} INFO - 25/10/09 03:00:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a095879b-73e3-4b4d-87b4-54ca584bf626
[2025-10-09T03:00:27.060+0000] {subprocess.py:93} INFO - 25/10/09 03:00:27 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-10-09T03:00:27.143+0000] {subprocess.py:93} INFO - 25/10/09 03:00:27 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-10-09T03:00:27.827+0000] {subprocess.py:93} INFO - 25/10/09 03:00:27 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-09T03:00:28.051+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-10-09T03:00:28.076+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-10-09T03:00:28.189+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar at spark://01b28d042a8a:40063/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.190+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar at spark://01b28d042a8a:40063/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.192+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://01b28d042a8a:40063/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.193+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://01b28d042a8a:40063/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759978825258
[2025-10-09T03:00:28.194+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://01b28d042a8a:40063/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.195+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:28.196+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://01b28d042a8a:40063/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1759978825258
[2025-10-09T03:00:28.198+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://01b28d042a8a:40063/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1759978825258
[2025-10-09T03:00:28.199+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://01b28d042a8a:40063/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1759978825258
[2025-10-09T03:00:28.200+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:28.201+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://01b28d042a8a:40063/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1759978825258
[2025-10-09T03:00:28.203+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.207+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:28.256+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.259+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:28.267+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.268+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-10-09T03:00:28.326+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759978825258
[2025-10-09T03:00:28.327+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/com.google.code.findbugs_jsr305-3.0.0.jar
[2025-10-09T03:00:28.336+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1759978825258
[2025-10-09T03:00:28.337+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.commons_commons-pool2-2.11.1.jar
[2025-10-09T03:00:28.347+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:28.348+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-10-09T03:00:28.632+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1759978825258
[2025-10-09T03:00:28.635+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.lz4_lz4-java-1.8.0.jar
[2025-10-09T03:00:28.799+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1759978825258
[2025-10-09T03:00:28.804+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-10-09T03:00:28.907+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1759978825258
[2025-10-09T03:00:28.911+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.slf4j_slf4j-api-2.0.7.jar
[2025-10-09T03:00:28.929+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:28.931+0000] {subprocess.py:93} INFO - 25/10/09 03:00:28 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-10-09T03:00:29.516+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO SparkContext: Added file file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1759978825258
[2025-10-09T03:00:29.522+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Utils: Copying /home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/commons-logging_commons-logging-1.1.3.jar
[2025-10-09T03:00:29.821+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Starting executor ID driver on host 01b28d042a8a
[2025-10-09T03:00:29.822+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: OS info Linux, 6.6.87.1-microsoft-standard-WSL2, amd64
[2025-10-09T03:00:29.824+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Java version 17.0.16
[2025-10-09T03:00:29.840+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-09T03:00:29.842+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2904be4d for default.
[2025-10-09T03:00:29.867+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:29.921+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:29.928+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:29.967+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Utils: /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-10-09T03:00:29.974+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:29.999+0000] {subprocess.py:93} INFO - 25/10/09 03:00:29 INFO Utils: /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-10-09T03:00:30.005+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:30.006+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:30.012+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759978825258
[2025-10-09T03:00:30.014+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/com.google.code.findbugs_jsr305-3.0.0.jar
[2025-10-09T03:00:30.019+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1759978825258
[2025-10-09T03:00:30.022+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.lz4_lz4-java-1.8.0.jar
[2025-10-09T03:00:30.028+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1759978825258
[2025-10-09T03:00:30.029+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.slf4j_slf4j-api-2.0.7.jar
[2025-10-09T03:00:30.043+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1759978825258
[2025-10-09T03:00:30.044+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.commons_commons-pool2-2.11.1.jar
[2025-10-09T03:00:30.054+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1759978825258
[2025-10-09T03:00:30.055+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/commons-logging_commons-logging-1.1.3.jar
[2025-10-09T03:00:30.063+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1759978825258
[2025-10-09T03:00:30.067+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-10-09T03:00:30.075+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1759978825258
[2025-10-09T03:00:30.088+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-10-09T03:00:30.105+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1759978825258
[2025-10-09T03:00:30.311+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO TransportClientFactory: Successfully created connection to 01b28d042a8a/172.21.0.4:40063 after 170 ms (0 ms spent in bootstraps)
[2025-10-09T03:00:30.334+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp13920464612845817370.tmp
[2025-10-09T03:00:30.408+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp13920464612845817370.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/com.google.code.findbugs_jsr305-3.0.0.jar
[2025-10-09T03:00:30.419+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/com.google.code.findbugs_jsr305-3.0.0.jar to class loader default
[2025-10-09T03:00:30.421+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:30.427+0000] {subprocess.py:93} INFO - 25/10/09 03:00:30 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14146996020510777954.tmp
[2025-10-09T03:00:31.110+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14146996020510777954.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-10-09T03:00:31.131+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
[2025-10-09T03:00:31.134+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1759978825258
[2025-10-09T03:00:31.135+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp4076973850091253719.tmp
[2025-10-09T03:00:31.152+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp4076973850091253719.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-10-09T03:00:31.159+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
[2025-10-09T03:00:31.161+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1759978825258
[2025-10-09T03:00:31.163+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp3649051972194075579.tmp
[2025-10-09T03:00:31.221+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp3649051972194075579.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-10-09T03:00:31.231+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
[2025-10-09T03:00:31.232+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:31.233+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp5813974796280168745.tmp
[2025-10-09T03:00:31.241+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp5813974796280168745.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:31.251+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar to class loader default
[2025-10-09T03:00:31.253+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1759978825258
[2025-10-09T03:00:31.255+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp4494866084847500569.tmp
[2025-10-09T03:00:31.259+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp4494866084847500569.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.commons_commons-pool2-2.11.1.jar
[2025-10-09T03:00:31.266+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
[2025-10-09T03:00:31.267+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1759978825258
[2025-10-09T03:00:31.268+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14354215255617238353.tmp
[2025-10-09T03:00:31.276+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14354215255617238353.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.lz4_lz4-java-1.8.0.jar
[2025-10-09T03:00:31.286+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.lz4_lz4-java-1.8.0.jar to class loader default
[2025-10-09T03:00:31.288+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1759978825258
[2025-10-09T03:00:31.290+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp8734675378415564498.tmp
[2025-10-09T03:00:31.484+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp8734675378415564498.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-10-09T03:00:31.496+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
[2025-10-09T03:00:31.498+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1759978825258
[2025-10-09T03:00:31.499+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp6948446043795876694.tmp
[2025-10-09T03:00:31.501+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp6948446043795876694.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/commons-logging_commons-logging-1.1.3.jar
[2025-10-09T03:00:31.508+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/commons-logging_commons-logging-1.1.3.jar to class loader default
[2025-10-09T03:00:31.510+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1759978825258
[2025-10-09T03:00:31.511+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14257946959712740074.tmp
[2025-10-09T03:00:31.515+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp14257946959712740074.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar
[2025-10-09T03:00:31.525+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar to class loader default
[2025-10-09T03:00:31.527+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Fetching spark://01b28d042a8a:40063/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1759978825258
[2025-10-09T03:00:31.528+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Fetching spark://01b28d042a8a:40063/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp6695121467328693894.tmp
[2025-10-09T03:00:31.534+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/fetchFileTemp6695121467328693894.tmp has been previously copied to /tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.slf4j_slf4j-api-2.0.7.jar
[2025-10-09T03:00:31.544+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Executor: Adding file:/tmp/spark-905ba0cc-3278-4546-b010-e15bcbf090e0/userFiles-1527ff8d-5bbf-47dd-a08a-04c66a56bc98/org.slf4j_slf4j-api-2.0.7.jar to class loader default
[2025-10-09T03:00:31.569+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44307.
[2025-10-09T03:00:31.571+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO NettyBlockTransferService: Server created on 01b28d042a8a:44307
[2025-10-09T03:00:31.576+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-09T03:00:31.598+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 01b28d042a8a, 44307, None)
[2025-10-09T03:00:31.612+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO BlockManagerMasterEndpoint: Registering block manager 01b28d042a8a:44307 with 434.4 MiB RAM, BlockManagerId(driver, 01b28d042a8a, 44307, None)
[2025-10-09T03:00:31.617+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 01b28d042a8a, 44307, None)
[2025-10-09T03:00:31.620+0000] {subprocess.py:93} INFO - 25/10/09 03:00:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 01b28d042a8a, 44307, None)
[2025-10-09T03:00:32.997+0000] {subprocess.py:93} INFO - 25/10/09 03:00:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-09T03:00:33.003+0000] {subprocess.py:93} INFO - 25/10/09 03:00:33 INFO SharedState: Warehouse path is 'file:/tmp/***tmp84nthkr_/spark-warehouse'.
[2025-10-09T03:00:41.532+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-10-09T03:00:41.637+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO ResolveWriteToStream: Checkpoint root /opt/***/checkpoints/orders_weather/kpi resolved to file:/opt/***/checkpoints/orders_weather/kpi.
[2025-10-09T03:00:41.638+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-10-09T03:00:41.888+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO MicroBatchExecution: Starting [id = 8c50bf01-a365-4e80-a390-cc640f6a9fc8, runId = ef6559c7-bd4a-4b5f-b610-3f79de6bea19]. Use file:/opt/***/checkpoints/orders_weather/kpi to store the query checkpoint.
[2025-10-09T03:00:41.897+0000] {subprocess.py:93} INFO - Model not found at /opt/models/revenue_model
[2025-10-09T03:00:41.905+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@500274cb] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@5d521d9a]
[2025-10-09T03:00:41.960+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO OffsetSeqLog: BatchIds found from listing: 0
[2025-10-09T03:00:41.985+0000] {subprocess.py:93} INFO - 25/10/09 03:00:41 INFO OffsetSeqLog: Getting latest batch 0
[2025-10-09T03:00:42.043+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO OffsetSeqLog: BatchIds found from listing: 0
[2025-10-09T03:00:42.044+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO OffsetSeqLog: Getting latest batch 0
[2025-10-09T03:00:42.056+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO CommitLog: BatchIds found from listing: 0
[2025-10-09T03:00:42.057+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO CommitLog: Getting latest batch 0
[2025-10-09T03:00:42.067+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO MicroBatchExecution: Resuming at batch 1 with committed offsets {KafkaV2[Subscribe[orders, weather]]: {"orders":{"0":112},"weather":{"0":4}}} and available offsets {KafkaV2[Subscribe[orders, weather]]: {"orders":{"0":112},"weather":{"0":4}}}
[2025-10-09T03:00:42.067+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO MicroBatchExecution: Stream started from {KafkaV2[Subscribe[orders, weather]]: {"orders":{"0":112},"weather":{"0":4}}}
[2025-10-09T03:00:42.140+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO AdminClientConfig: AdminClientConfig values:
[2025-10-09T03:00:42.141+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-10-09T03:00:42.142+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-10-09T03:00:42.143+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-10-09T03:00:42.144+0000] {subprocess.py:93} INFO - 	client.id =
[2025-10-09T03:00:42.144+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-10-09T03:00:42.145+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-10-09T03:00:42.146+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-10-09T03:00:42.147+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-10-09T03:00:42.147+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-10-09T03:00:42.148+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-10-09T03:00:42.149+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-10-09T03:00:42.150+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-10-09T03:00:42.151+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-10-09T03:00:42.152+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-10-09T03:00:42.153+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-10-09T03:00:42.154+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-10-09T03:00:42.155+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-10-09T03:00:42.156+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-10-09T03:00:42.157+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-10-09T03:00:42.158+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-10-09T03:00:42.158+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-10-09T03:00:42.159+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-10-09T03:00:42.160+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-10-09T03:00:42.160+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-10-09T03:00:42.161+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-10-09T03:00:42.162+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-10-09T03:00:42.163+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-10-09T03:00:42.164+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-10-09T03:00:42.165+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-10-09T03:00:42.165+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-10-09T03:00:42.166+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-10-09T03:00:42.167+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-10-09T03:00:42.168+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-10-09T03:00:42.168+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-10-09T03:00:42.169+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-10-09T03:00:42.170+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-10-09T03:00:42.171+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-10-09T03:00:42.172+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-10-09T03:00:42.173+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-10-09T03:00:42.173+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-10-09T03:00:42.174+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-10-09T03:00:42.175+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-10-09T03:00:42.179+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-10-09T03:00:42.180+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-10-09T03:00:42.180+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-10-09T03:00:42.181+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-10-09T03:00:42.182+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-10-09T03:00:42.183+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-10-09T03:00:42.183+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-10-09T03:00:42.184+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-10-09T03:00:42.184+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-10-09T03:00:42.185+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-10-09T03:00:42.185+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-10-09T03:00:42.186+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-10-09T03:00:42.187+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-10-09T03:00:42.188+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-10-09T03:00:42.188+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-10-09T03:00:42.189+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-10-09T03:00:42.189+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-10-09T03:00:42.190+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-10-09T03:00:42.191+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-10-09T03:00:42.192+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-10-09T03:00:42.193+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-10-09T03:00:42.193+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-10-09T03:00:42.194+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-10-09T03:00:42.195+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-10-09T03:00:42.195+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-10-09T03:00:42.196+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-10-09T03:00:42.197+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-10-09T03:00:42.197+0000] {subprocess.py:93} INFO - 
[2025-10-09T03:00:42.367+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-10-09T03:00:42.391+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO AppInfoParser: Kafka version: 3.4.1
[2025-10-09T03:00:42.393+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-10-09T03:00:42.394+0000] {subprocess.py:93} INFO - 25/10/09 03:00:42 INFO AppInfoParser: Kafka startTimeMs: 1759978842367
[2025-10-09T03:00:53.415+0000] {subprocess.py:93} INFO - 25/10/09 03:00:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:03.415+0000] {subprocess.py:93} INFO - 25/10/09 03:01:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:13.416+0000] {subprocess.py:93} INFO - 25/10/09 03:01:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:23.426+0000] {subprocess.py:93} INFO - 25/10/09 03:01:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:33.434+0000] {subprocess.py:93} INFO - 25/10/09 03:01:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:43.435+0000] {subprocess.py:93} INFO - 25/10/09 03:01:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:01:53.445+0000] {subprocess.py:93} INFO - 25/10/09 03:01:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:03.458+0000] {subprocess.py:93} INFO - 25/10/09 03:02:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:13.465+0000] {subprocess.py:93} INFO - 25/10/09 03:02:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:23.466+0000] {subprocess.py:93} INFO - 25/10/09 03:02:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:33.477+0000] {subprocess.py:93} INFO - 25/10/09 03:02:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:43.484+0000] {subprocess.py:93} INFO - 25/10/09 03:02:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:02:53.488+0000] {subprocess.py:93} INFO - 25/10/09 03:02:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:03.491+0000] {subprocess.py:93} INFO - 25/10/09 03:03:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:13.506+0000] {subprocess.py:93} INFO - 25/10/09 03:03:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:23.538+0000] {subprocess.py:93} INFO - 25/10/09 03:03:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:33.529+0000] {subprocess.py:93} INFO - 25/10/09 03:03:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:43.532+0000] {subprocess.py:93} INFO - 25/10/09 03:03:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:03:53.535+0000] {subprocess.py:93} INFO - 25/10/09 03:03:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:03.538+0000] {subprocess.py:93} INFO - 25/10/09 03:04:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:13.545+0000] {subprocess.py:93} INFO - 25/10/09 03:04:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:23.557+0000] {subprocess.py:93} INFO - 25/10/09 03:04:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:33.570+0000] {subprocess.py:93} INFO - 25/10/09 03:04:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:43.576+0000] {subprocess.py:93} INFO - 25/10/09 03:04:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:04:53.578+0000] {subprocess.py:93} INFO - 25/10/09 03:04:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:03.589+0000] {subprocess.py:93} INFO - 25/10/09 03:05:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:13.599+0000] {subprocess.py:93} INFO - 25/10/09 03:05:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:23.602+0000] {subprocess.py:93} INFO - 25/10/09 03:05:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:33.606+0000] {subprocess.py:93} INFO - 25/10/09 03:05:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:43.299+0000] {subprocess.py:93} INFO - 25/10/09 03:05:43 INFO NetworkClient: [AdminClient clientId=adminclient-1] Node -1 disconnected.
[2025-10-09T03:05:43.608+0000] {subprocess.py:93} INFO - 25/10/09 03:05:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:05:53.612+0000] {subprocess.py:93} INFO - 25/10/09 03:05:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:03.625+0000] {subprocess.py:93} INFO - 25/10/09 03:06:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:13.637+0000] {subprocess.py:93} INFO - 25/10/09 03:06:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:23.643+0000] {subprocess.py:93} INFO - 25/10/09 03:06:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:33.646+0000] {subprocess.py:93} INFO - 25/10/09 03:06:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:43.647+0000] {subprocess.py:93} INFO - 25/10/09 03:06:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:06:53.652+0000] {subprocess.py:93} INFO - 25/10/09 03:06:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:03.658+0000] {subprocess.py:93} INFO - 25/10/09 03:07:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:13.666+0000] {subprocess.py:93} INFO - 25/10/09 03:07:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:23.677+0000] {subprocess.py:93} INFO - 25/10/09 03:07:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:33.684+0000] {subprocess.py:93} INFO - 25/10/09 03:07:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:43.697+0000] {subprocess.py:93} INFO - 25/10/09 03:07:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:07:53.697+0000] {subprocess.py:93} INFO - 25/10/09 03:07:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:03.699+0000] {subprocess.py:93} INFO - 25/10/09 03:08:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:13.700+0000] {subprocess.py:93} INFO - 25/10/09 03:08:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:23.703+0000] {subprocess.py:93} INFO - 25/10/09 03:08:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:33.712+0000] {subprocess.py:93} INFO - 25/10/09 03:08:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:43.718+0000] {subprocess.py:93} INFO - 25/10/09 03:08:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:08:53.718+0000] {subprocess.py:93} INFO - 25/10/09 03:08:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:03.729+0000] {subprocess.py:93} INFO - 25/10/09 03:09:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:13.736+0000] {subprocess.py:93} INFO - 25/10/09 03:09:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:23.744+0000] {subprocess.py:93} INFO - 25/10/09 03:09:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:33.745+0000] {subprocess.py:93} INFO - 25/10/09 03:09:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:43.753+0000] {subprocess.py:93} INFO - 25/10/09 03:09:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:09:53.762+0000] {subprocess.py:93} INFO - 25/10/09 03:09:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:03.768+0000] {subprocess.py:93} INFO - 25/10/09 03:10:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:13.769+0000] {subprocess.py:93} INFO - 25/10/09 03:10:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:23.780+0000] {subprocess.py:93} INFO - 25/10/09 03:10:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:33.782+0000] {subprocess.py:93} INFO - 25/10/09 03:10:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:43.788+0000] {subprocess.py:93} INFO - 25/10/09 03:10:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:10:53.800+0000] {subprocess.py:93} INFO - 25/10/09 03:10:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:03.803+0000] {subprocess.py:93} INFO - 25/10/09 03:11:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:13.807+0000] {subprocess.py:93} INFO - 25/10/09 03:11:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:23.813+0000] {subprocess.py:93} INFO - 25/10/09 03:11:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:33.815+0000] {subprocess.py:93} INFO - 25/10/09 03:11:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:43.825+0000] {subprocess.py:93} INFO - 25/10/09 03:11:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:11:53.837+0000] {subprocess.py:93} INFO - 25/10/09 03:11:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:03.843+0000] {subprocess.py:93} INFO - 25/10/09 03:12:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:13.854+0000] {subprocess.py:93} INFO - 25/10/09 03:12:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:23.865+0000] {subprocess.py:93} INFO - 25/10/09 03:12:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:33.872+0000] {subprocess.py:93} INFO - 25/10/09 03:12:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:43.876+0000] {subprocess.py:93} INFO - 25/10/09 03:12:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:12:53.886+0000] {subprocess.py:93} INFO - 25/10/09 03:12:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:03.895+0000] {subprocess.py:93} INFO - 25/10/09 03:13:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:13.904+0000] {subprocess.py:93} INFO - 25/10/09 03:13:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:23.907+0000] {subprocess.py:93} INFO - 25/10/09 03:13:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:33.915+0000] {subprocess.py:93} INFO - 25/10/09 03:13:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:43.922+0000] {subprocess.py:93} INFO - 25/10/09 03:13:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:13:53.929+0000] {subprocess.py:93} INFO - 25/10/09 03:13:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:03.929+0000] {subprocess.py:93} INFO - 25/10/09 03:14:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:13.930+0000] {subprocess.py:93} INFO - 25/10/09 03:14:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:23.932+0000] {subprocess.py:93} INFO - 25/10/09 03:14:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:33.936+0000] {subprocess.py:93} INFO - 25/10/09 03:14:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:43.946+0000] {subprocess.py:93} INFO - 25/10/09 03:14:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:14:53.962+0000] {subprocess.py:93} INFO - 25/10/09 03:14:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:15:03.972+0000] {subprocess.py:93} INFO - 25/10/09 03:15:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-10-09T03:15:05.946+0000] {local_task_job_runner.py:313} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-10-09T03:15:05.961+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-09T03:15:05.966+0000] {process_utils.py:132} INFO - Sending 15 to group 2560. PIDs of all processes in the group: [2561, 2621, 2560]
[2025-10-09T03:15:05.992+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 2560
[2025-10-09T03:15:06.008+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-10-09T03:15:06.039+0000] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2025-10-09T03:15:06.080+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-09T03:15:06.353+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=2560, status='terminated', exitcode=0, started='03:00:08') (2560) terminated with exit code 0
[2025-10-09T03:15:06.728+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=2621, status='terminated', started='03:00:19') (2621) terminated with exit code None
[2025-10-09T03:15:07.580+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=2561, status='terminated', started='03:00:08') (2561) terminated with exit code None
